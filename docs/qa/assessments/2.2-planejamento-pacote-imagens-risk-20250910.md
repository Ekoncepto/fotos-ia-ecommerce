# Risk Profile: Story 2.2

Date: 2025-09-10
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 9
- Critical Risks: 0
- High Risks: 2
- Risk Score: 64/100

## High Risks Requiring Attention

### 1. [BUS-001]: Poor AI plan quality reduces user value
**Score: 6 (High)**
**Probability**: Medium — Planning LLMs may hallucinate or mis-prioritize.
**Impact**: High — Users receive ineffective image sets; churn risk.
**Mitigation**:
- Provide strong system prompts, category heuristics, and guardrails.
- Human-readable plan with categories limited to supported types.
- A/B evaluate plan outcomes vs baseline (fixed two images).
**Testing Focus**: Golden tests for representative products; plan sanity checks.

### 2. [TECH-001]: Planner→Generator integration failures
**Score: 6 (High)**
**Probability**: Medium — Mapping plan intents to generator parameters is brittle.
**Impact**: High — Generation fails or mismatches planned types.
**Mitigation**:
- Strict schema for planned items; validation before execution.
- Integration tests covering mapping and fallback to baseline flow.
- Circuit breaker to revert to manual generation when plan invalid.
**Testing Focus**: Contract tests across intent→prompt template mapping.

## Risk Distribution

### By Category
- Security: 0
- Technical: 4
- Performance/Cost: 2
- Data: 1
- Business: 2
- Operational: 0

### By Component
- Planner service/LLM: 5
- Image generator integration: 4

## Detailed Risk Register

| Risk ID  | Description                                                                 | Probability | Impact     | Score | Priority | Mitigation Actions |
| -------- | --------------------------------------------------------------------------- | ----------- | ---------- | ----- | -------- | ------------------ |
| BUS-001  | Inadequate plan quality; irrelevant or redundant images.                    | Medium (2)  | High (3)   | 6     | High     | Guardrails, heuristics, golden set checks, A/B against baseline. |
| TECH-001 | Planner→generator mapping errors, unsupported combinations.                 | Medium (2)  | High (3)   | 6     | High     | Strict schema, validation, integration tests, fallback path. |
| PERF-001 | Increased latency from planning step.                                       | Medium (2)  | Medium (2) | 4     | Medium   | Cache prompts, reuse embeddings, parallelize where safe. |
| COST-001 | Higher API costs due to additional LLM calls.                               | Medium (2)  | Medium (2) | 4     | Medium   | Budget guardrails, sampling, early exit on confident plan. |
| TECH-002 | Prompt/template drift over time.                                            | Medium (2)  | Medium (2) | 4     | Medium   | Versioned templates, regression tests for prompts. |
| DATA-001 | Bias/drift leading to unfair or inconsistent plans.                         | Low (1)     | High (3)   | 3     | Low      | Dataset diversity checks; monitoring of plan distributions. |
| TECH-003 | Failure to fallback to manual baseline flow.                                | Low (1)     | High (3)   | 3     | Low      | Circuit breakers, feature flag gating. |
| BUS-002  | Misaligned categories vs user verticals.                                    | Medium (2)  | Low (1)    | 2     | Low      | Category taxonomy alignment; explicit mapping table. |
| TECH-004 | Observability gaps (no plan or execution trace).                            | Low (1)     | Medium (2) | 2     | Low      | Structured logs; plan IDs; trace linkage to outputs. |

## Risk-Based Testing Strategy

### Priority 1: High Risk Tests
- Golden product set: verify planned image types and mapping to generator.
- Integration tests: schema validation, fallback to baseline when invalid.

### Priority 2: Medium Risk Tests
- Latency budget tests with planner on/off.
- Prompt regression tests across template versions.

### Priority 3: Low Risk Tests
- Bias/drift sampling checks across categories.
- Observability: ensure plan IDs and execution traces exist.

## Risk Acceptance Criteria

### Must Fix Before Production
- Planner→generator contract validation and fallback; golden plan sanity.

### Can Deploy With Mitigation
- Latency/cost controls; prompt versioning and monitoring.

### Accepted Risks
- Minor category misalignment initially, addressed iteratively.

## Monitoring Requirements

- Track planner latency, plan acceptance rate, and fallback frequency.
- Monitor generator success by planned type and final user selection rate.

